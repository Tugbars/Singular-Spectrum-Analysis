{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSA Demonstration: Denoising, Trend Extraction, and Periodic Components\n",
    "\n",
    "This notebook demonstrates the capabilities of the MKL-optimized SSA implementation:\n",
    "\n",
    "1. **Denoising**: Separating signal from noise\n",
    "2. **Trend Extraction**: Isolating underlying trends\n",
    "3. **Periodic Extraction**: Identifying and extracting cyclical patterns\n",
    "4. **Forecasting**: Predicting future values using LRF\n",
    "5. **MSSA**: Multivariate analysis of correlated series\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, ensure `libssa.so` is built:\n",
    "```bash\n",
    "source /opt/intel/oneapi/setvars.sh\n",
    "gcc -shared -fPIC -O3 -o libssa.so ssa_wrapper.c \\\n",
    "    -DSSA_OPT_IMPLEMENTATION -DSSA_USE_MKL \\\n",
    "    -I${MKLROOT}/include -L${MKLROOT}/lib/intel64 -lmkl_rt -lm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ssa_wrapper import SSA, MSSA\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Denoising\n",
    "\n",
    "SSA separates deterministic signal from stochastic noise by concentrating signal energy in the first few singular components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal + noise\n",
    "N = 500\n",
    "t = np.linspace(0, 4*np.pi, N)\n",
    "\n",
    "clean_signal = np.sin(t) + 0.5*np.sin(3*t)  # Two harmonics\n",
    "noise = 0.5 * np.random.randn(N)\n",
    "noisy_signal = clean_signal + noise\n",
    "\n",
    "# Apply SSA\n",
    "ssa = SSA(noisy_signal, L=100)\n",
    "ssa.decompose(k=20)\n",
    "\n",
    "# Reconstruct with first few components (signal)\n",
    "denoised = ssa.reconstruct([0, 1, 2, 3])  # First 4 components\n",
    "extracted_noise = ssa.get_noise(noise_start=4)\n",
    "\n",
    "# Compute metrics\n",
    "snr_before = 10 * np.log10(np.var(clean_signal) / np.var(noise))\n",
    "snr_after = 10 * np.log10(np.var(clean_signal) / np.var(denoised - clean_signal))\n",
    "\n",
    "print(f\"SNR before: {snr_before:.1f} dB\")\n",
    "print(f\"SNR after:  {snr_after:.1f} dB\")\n",
    "print(f\"Improvement: {snr_after - snr_before:.1f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Original signals\n",
    "axes[0, 0].plot(t, clean_signal, 'g-', lw=2, label='Clean signal', alpha=0.8)\n",
    "axes[0, 0].plot(t, noisy_signal, 'b-', lw=0.5, alpha=0.5, label='Noisy signal')\n",
    "axes[0, 0].set_title('Input: Clean Signal + Noise')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_xlabel('t')\n",
    "\n",
    "# Denoised result\n",
    "axes[0, 1].plot(t, clean_signal, 'g-', lw=2, label='Clean signal', alpha=0.8)\n",
    "axes[0, 1].plot(t, denoised, 'r-', lw=1.5, label='SSA denoised')\n",
    "axes[0, 1].set_title(f'SSA Denoising (SNR: {snr_before:.1f}→{snr_after:.1f} dB)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_xlabel('t')\n",
    "\n",
    "# Residual comparison\n",
    "axes[1, 0].plot(t, noise, 'b-', lw=0.5, alpha=0.7, label='True noise')\n",
    "axes[1, 0].plot(t, extracted_noise, 'r-', lw=0.5, alpha=0.7, label='SSA extracted noise')\n",
    "axes[1, 0].set_title('Noise: True vs Extracted')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_xlabel('t')\n",
    "\n",
    "# Singular value spectrum\n",
    "variances = [ssa.variance_explained(i, i) for i in range(min(15, ssa.n_components))]\n",
    "axes[1, 1].bar(range(len(variances)), variances, color='steelblue', alpha=0.8)\n",
    "axes[1, 1].axvline(x=3.5, color='red', linestyle='--', label='Signal/Noise cutoff')\n",
    "axes[1, 1].set_title('Singular Value Spectrum (Variance per Component)')\n",
    "axes[1, 1].set_xlabel('Component')\n",
    "axes[1, 1].set_ylabel('Variance Explained')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ssa_denoising.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Trend Extraction\n",
    "\n",
    "SSA extracts smooth trends without the lag of moving averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate price-like series: trend + seasonality + noise\n",
    "N = 600\n",
    "t = np.arange(N)\n",
    "\n",
    "trend = 100 + 0.05*t + 5*np.sin(2*np.pi*t/400)  # Slow drift + very slow cycle\n",
    "seasonal = 3*np.sin(2*np.pi*t/50)  # ~50 period cycle\n",
    "noise = 1.5*np.random.randn(N)\n",
    "\n",
    "price = trend + seasonal + noise\n",
    "\n",
    "# SSA trend extraction\n",
    "ssa = SSA(price, L=120)\n",
    "ssa.decompose(k=20)\n",
    "\n",
    "ssa_trend = ssa.get_trend()  # Component 0\n",
    "\n",
    "# Compare with moving averages\n",
    "def moving_average(x, window):\n",
    "    return np.convolve(x, np.ones(window)/window, mode='same')\n",
    "\n",
    "ma_50 = moving_average(price, 50)\n",
    "ma_100 = moving_average(price, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Full view\n",
    "axes[0].plot(t, price, 'gray', lw=0.5, alpha=0.7, label='Price')\n",
    "axes[0].plot(t, trend, 'g-', lw=2, label='True trend', alpha=0.8)\n",
    "axes[0].plot(t, ssa_trend, 'r-', lw=2, label='SSA trend')\n",
    "axes[0].plot(t, ma_50, 'b--', lw=1, label='MA(50)', alpha=0.7)\n",
    "axes[0].plot(t, ma_100, 'purple', ls='--', lw=1, label='MA(100)', alpha=0.7)\n",
    "axes[0].set_title('Trend Extraction: SSA vs Moving Averages')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Price')\n",
    "\n",
    "# Zoom on turning point (to show lag difference)\n",
    "zoom_start, zoom_end = 150, 250\n",
    "axes[1].plot(t[zoom_start:zoom_end], price[zoom_start:zoom_end], 'gray', lw=0.8, alpha=0.7, label='Price')\n",
    "axes[1].plot(t[zoom_start:zoom_end], trend[zoom_start:zoom_end], 'g-', lw=2.5, label='True trend')\n",
    "axes[1].plot(t[zoom_start:zoom_end], ssa_trend[zoom_start:zoom_end], 'r-', lw=2, label='SSA trend')\n",
    "axes[1].plot(t[zoom_start:zoom_end], ma_50[zoom_start:zoom_end], 'b--', lw=1.5, label='MA(50)')\n",
    "axes[1].plot(t[zoom_start:zoom_end], ma_100[zoom_start:zoom_end], 'purple', ls='--', lw=1.5, label='MA(100)')\n",
    "axes[1].set_title('Zoomed: Notice MA Lag vs SSA')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ssa_trend.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Compute RMSE\n",
    "print(f\"RMSE (SSA trend):  {np.sqrt(np.mean((ssa_trend - trend)**2)):.3f}\")\n",
    "print(f\"RMSE (MA-50):      {np.sqrt(np.mean((ma_50 - trend)**2)):.3f}\")\n",
    "print(f\"RMSE (MA-100):     {np.sqrt(np.mean((ma_100 - trend)**2)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Periodic Component Extraction\n",
    "\n",
    "SSA identifies periodic signals as pairs of components with nearly equal singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-frequency signal\n",
    "N = 500\n",
    "t = np.arange(N)\n",
    "\n",
    "trend = 50 + 0.02*t\n",
    "period1 = 4*np.sin(2*np.pi*t/60)   # Period 60\n",
    "period2 = 2*np.sin(2*np.pi*t/25)   # Period 25 \n",
    "period3 = 1*np.sin(2*np.pi*t/12)   # Period 12\n",
    "noise = 0.8*np.random.randn(N)\n",
    "\n",
    "signal = trend + period1 + period2 + period3 + noise\n",
    "\n",
    "# SSA decomposition\n",
    "ssa = SSA(signal, L=100)\n",
    "ssa.decompose(k=20)\n",
    "\n",
    "# Find periodic pairs automatically\n",
    "pairs = ssa.find_periodic_pairs(max_pairs=10, sv_tol=0.15, wcorr_thresh=0.4)\n",
    "print(f\"Detected periodic pairs: {pairs}\")\n",
    "\n",
    "# Extract components\n",
    "ssa_trend = ssa.reconstruct([0])\n",
    "\n",
    "# Try to identify which pair corresponds to which frequency\n",
    "if len(pairs) >= 1:\n",
    "    ssa_period1 = ssa.reconstruct(list(pairs[0]))\n",
    "if len(pairs) >= 2:\n",
    "    ssa_period2 = ssa.reconstruct(list(pairs[1]))\n",
    "if len(pairs) >= 3:\n",
    "    ssa_period3 = ssa.reconstruct(list(pairs[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Original signal\n",
    "axes[0, 0].plot(t, signal, 'b-', lw=0.5, alpha=0.7)\n",
    "axes[0, 0].plot(t, trend, 'r-', lw=2, label='True trend')\n",
    "axes[0, 0].set_title('Original Signal (Trend + 3 Periodicities + Noise)')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# W-correlation matrix\n",
    "W = ssa.wcorr_matrix()\n",
    "im = axes[0, 1].imshow(np.abs(W[:12, :12]), cmap='RdBu_r', vmin=0, vmax=1)\n",
    "axes[0, 1].set_title('W-Correlation Matrix (|ρ|)')\n",
    "axes[0, 1].set_xlabel('Component')\n",
    "axes[0, 1].set_ylabel('Component')\n",
    "plt.colorbar(im, ax=axes[0, 1], shrink=0.8)\n",
    "\n",
    "# Extracted periodicities\n",
    "axes[1, 0].plot(t, period1, 'g-', lw=2, alpha=0.5, label='True P=60')\n",
    "if len(pairs) >= 1:\n",
    "    axes[1, 0].plot(t, ssa_period1, 'r-', lw=1.5, label=f'SSA pair {pairs[0]}')\n",
    "axes[1, 0].plot(t, period2, 'b-', lw=2, alpha=0.5, label='True P=25')\n",
    "if len(pairs) >= 2:\n",
    "    axes[1, 0].plot(t, ssa_period2, 'orange', lw=1.5, label=f'SSA pair {pairs[1]}')\n",
    "axes[1, 0].set_title('Periodic Component Extraction')\n",
    "axes[1, 0].legend(ncol=2)\n",
    "axes[1, 0].set_xlim(0, 200)  # Zoom for clarity\n",
    "\n",
    "# Singular value spectrum with pairs highlighted\n",
    "n_show = 15\n",
    "sigmas = [np.sqrt(ssa.variance_explained(i, i) * 100) for i in range(n_show)]  # Relative scale\n",
    "colors = ['steelblue'] * n_show\n",
    "for p in pairs:\n",
    "    for idx in p:\n",
    "        if idx < n_show:\n",
    "            colors[idx] = 'red'\n",
    "\n",
    "axes[1, 1].bar(range(n_show), sigmas, color=colors, alpha=0.8)\n",
    "axes[1, 1].set_title('Singular Values (red = periodic pairs)')\n",
    "axes[1, 1].set_xlabel('Component')\n",
    "axes[1, 1].set_ylabel('Relative Magnitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ssa_periodic.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Forecasting with LRF\n",
    "\n",
    "SSA uses the Linear Recurrence Formula to extrapolate the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate signal with trend + seasonality\n",
    "N = 400\n",
    "N_forecast = 100\n",
    "t_full = np.arange(N + N_forecast)\n",
    "\n",
    "# True signal (known for entire range)\n",
    "true_trend = 100 + 0.03*t_full\n",
    "true_seasonal = 5*np.sin(2*np.pi*t_full/50)\n",
    "true_signal = true_trend + true_seasonal\n",
    "\n",
    "# Observed signal (only first N points, with noise)\n",
    "noise = 1.0*np.random.randn(N)\n",
    "observed = true_signal[:N] + noise\n",
    "\n",
    "# Fit SSA on observed data\n",
    "ssa = SSA(observed, L=80)\n",
    "ssa.decompose(k=20)\n",
    "\n",
    "# Forecast\n",
    "signal_components = [0, 1, 2]  # Trend + first periodic pair\n",
    "full_reconstruction = ssa.forecast_full(signal_components, N_forecast)\n",
    "\n",
    "reconstruction = full_reconstruction[:N]\n",
    "forecast = full_reconstruction[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Full view\n",
    "axes[0].plot(t_full[:N], observed, 'gray', lw=0.5, alpha=0.5, label='Observed')\n",
    "axes[0].plot(t_full, true_signal, 'g-', lw=2, alpha=0.7, label='True signal')\n",
    "axes[0].plot(t_full[:N], reconstruction, 'b-', lw=1.5, label='SSA reconstruction')\n",
    "axes[0].plot(t_full[N:], forecast, 'r-', lw=2, label='SSA forecast')\n",
    "axes[0].axvline(x=N, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0].fill_between([N, N+N_forecast], -10, 200, alpha=0.1, color='red')\n",
    "axes[0].set_title('SSA Forecasting')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].set_ylim(90, 130)\n",
    "\n",
    "# Forecast zoom\n",
    "t_forecast = t_full[N:]\n",
    "axes[1].plot(t_forecast, true_signal[N:], 'g-', lw=2.5, label='True signal')\n",
    "axes[1].plot(t_forecast, forecast, 'r-', lw=2, label='SSA forecast')\n",
    "axes[1].fill_between(t_forecast, true_signal[N:], forecast, alpha=0.3, color='red')\n",
    "axes[1].set_title('Forecast Region (Zoomed)')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ssa_forecast.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Compute forecast error\n",
    "forecast_rmse = np.sqrt(np.mean((forecast - true_signal[N:])**2))\n",
    "forecast_mape = np.mean(np.abs((forecast - true_signal[N:]) / true_signal[N:])) * 100\n",
    "print(f\"Forecast RMSE: {forecast_rmse:.3f}\")\n",
    "print(f\"Forecast MAPE: {forecast_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. MSSA: Multivariate Analysis\n",
    "\n",
    "MSSA extracts common factors from correlated time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 4 correlated \"sector ETFs\"\n",
    "N = 400\n",
    "t = np.arange(N)\n",
    "\n",
    "# Common market factor\n",
    "market = 100 + 0.05*t + 8*np.sin(2*np.pi*t/100)\n",
    "\n",
    "# Sector-specific factors\n",
    "sector_betas = [1.0, 0.8, 1.2, 0.6]  # Market exposure\n",
    "sector_offsets = [0, 20, -10, 40]  # Base level\n",
    "sector_noise = [1.5, 2.0, 1.8, 2.5]  # Idiosyncratic vol\n",
    "\n",
    "# Generate series\n",
    "X = np.zeros((4, N))\n",
    "for i in range(4):\n",
    "    X[i] = sector_offsets[i] + sector_betas[i] * market + sector_noise[i] * np.random.randn(N)\n",
    "\n",
    "# Apply MSSA\n",
    "mssa = MSSA(X, L=80)\n",
    "mssa.decompose(k=15)\n",
    "\n",
    "print(f\"Variance explained by first 3 components: {mssa.variance_explained(0, 2):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract common factor from each series\n",
    "common = mssa.reconstruct_all([0])  # First component = market\n",
    "\n",
    "# Series contributions\n",
    "contrib = mssa.series_contributions()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Original series\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "for i in range(4):\n",
    "    axes[0, 0].plot(t, X[i], color=colors[i], lw=0.5, alpha=0.7, label=f'Series {i}')\n",
    "axes[0, 0].set_title('Original Series (4 Correlated ETFs)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "\n",
    "# Extracted common factor vs true market\n",
    "axes[0, 1].plot(t, market, 'k-', lw=2, label='True market factor', alpha=0.7)\n",
    "for i in range(4):\n",
    "    # Scale common factor to match market (different betas)\n",
    "    scaled = common[i] - np.mean(common[i]) + np.mean(market)\n",
    "    axes[0, 1].plot(t, common[i], color=colors[i], lw=1, alpha=0.5, label=f'Common from S{i}')\n",
    "axes[0, 1].set_title('Extracted Common Factor vs True Market')\n",
    "axes[0, 1].legend(ncol=2)\n",
    "axes[0, 1].set_xlabel('Time')\n",
    "\n",
    "# Series contributions heatmap\n",
    "im = axes[1, 0].imshow(contrib[:, :8], aspect='auto', cmap='YlOrRd')\n",
    "axes[1, 0].set_title('Series Contributions to Components')\n",
    "axes[1, 0].set_xlabel('Component')\n",
    "axes[1, 0].set_ylabel('Series')\n",
    "axes[1, 0].set_yticks(range(4))\n",
    "axes[1, 0].set_yticklabels([f'S{i}' for i in range(4)])\n",
    "plt.colorbar(im, ax=axes[1, 0], shrink=0.8)\n",
    "\n",
    "# Residuals (idiosyncratic)\n",
    "residuals = mssa.reconstruct_all(list(range(2, 10)))  # Components 2+ = idiosyncratic\n",
    "for i in range(4):\n",
    "    axes[1, 1].plot(t, residuals[i], color=colors[i], lw=0.5, alpha=0.7, label=f'Residual {i}')\n",
    "axes[1, 1].set_title('Idiosyncratic Residuals (should be uncorrelated)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_xlabel('Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mssa_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Compute residual correlations\n",
    "print(\"\\nResidual correlations (should be low):\")\n",
    "for i in range(4):\n",
    "    for j in range(i+1, 4):\n",
    "        corr = np.corrcoef(residuals[i], residuals[j])[0, 1]\n",
    "        print(f\"  Series {i} vs {j}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Performance Benchmark\n",
    "\n",
    "Compare decomposition methods and measure throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Generate large signal\n",
    "N = 5000\n",
    "L = 1000\n",
    "k = 50\n",
    "\n",
    "signal = np.cumsum(np.random.randn(N)) + 10*np.sin(2*np.pi*np.arange(N)/100)\n",
    "\n",
    "print(f\"Signal: N={N}, L={L}, k={k}\")\n",
    "print(f\"Hankel matrix: {L} × {N-L+1} = {L*(N-L+1):,} elements\")\n",
    "print()\n",
    "\n",
    "# Benchmark randomized SVD\n",
    "start = time.perf_counter()\n",
    "ssa = SSA(signal, L=L)\n",
    "ssa.decompose(k=k, method='randomized')\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Randomized SVD: {elapsed*1000:.1f} ms\")\n",
    "\n",
    "# Benchmark block method\n",
    "start = time.perf_counter()\n",
    "ssa2 = SSA(signal, L=L)\n",
    "ssa2.decompose(k=k, method='block')\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Block method:   {elapsed*1000:.1f} ms\")\n",
    "\n",
    "# Variance explained should be similar\n",
    "print(f\"\\nVariance explained (first 10):\")\n",
    "print(f\"  Randomized: {ssa.variance_explained(0, 9):.4f}\")\n",
    "print(f\"  Block:      {ssa2.variance_explained(0, 9):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This MKL-optimized SSA implementation provides:\n",
    "\n",
    "| Feature | Method | Typical Use |\n",
    "|---------|--------|-------------|\n",
    "| **Denoising** | `reconstruct([0..k])` | Clean price data |\n",
    "| **Trend** | `get_trend()` | Identify direction |\n",
    "| **Periodicity** | `find_periodic_pairs()` | Seasonality detection |\n",
    "| **Forecast** | `forecast()` | Price prediction |\n",
    "| **Multivariate** | `MSSA` | Pairs trading, factor extraction |\n",
    "\n",
    "Performance: ~20-40ms for N=5000, L=1000, k=50 using randomized SVD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
