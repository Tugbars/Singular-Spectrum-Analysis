{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSA Challenging Signals Test\n",
    "\n",
    "Testing SSA on difficult real-world scenarios:\n",
    "1. **Very Low SNR** - Can we recover signal from heavy noise?\n",
    "2. **Close Frequencies** - Can we separate f=1.0 Hz from f=1.1 Hz?\n",
    "3. **Non-stationary** - Amplitude/frequency modulation\n",
    "4. **Regime Changes** - Structural breaks in the data\n",
    "5. **Outliers & Spikes** - Robustness to anomalies\n",
    "6. **Real Financial Data** - Simulated stock prices\n",
    "7. **Chirp Signal** - Continuously varying frequency\n",
    "8. **Multiple Trends** - Polynomial + periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ssa_wrapper import SSA, MSSA\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "plt.rcParams['font.size'] = 11\n",
    "np.random.seed(42)\n",
    "\n",
    "def snr_db(clean, noisy):\n",
    "    \"\"\"Signal-to-noise ratio in dB.\"\"\"\n",
    "    return 10 * np.log10(np.var(clean) / np.var(noisy - clean))\n",
    "\n",
    "def rmse(a, b):\n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extreme Low SNR (-6 dB to +6 dB)\n",
    "\n",
    "At -6 dB, noise power is 4x signal power. This is brutal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "t = np.linspace(0, 10, N)\n",
    "clean = np.sin(2*np.pi*t) + 0.5*np.sin(4*np.pi*t)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "\n",
    "for idx, target_snr in enumerate([-6, -3, 0, 3, 6, 10]):\n",
    "    ax = axes[idx//3, idx%3]\n",
    "    \n",
    "    # Generate noise for target SNR\n",
    "    noise_std = np.sqrt(np.var(clean) / (10**(target_snr/10)))\n",
    "    noise = noise_std * np.random.randn(N)\n",
    "    noisy = clean + noise\n",
    "    \n",
    "    # SSA\n",
    "    ssa = SSA(noisy, L=100)\n",
    "    ssa.decompose(k=20)\n",
    "    denoised = ssa.reconstruct([0, 1, 2, 3])\n",
    "    \n",
    "    in_snr = snr_db(clean, noisy)\n",
    "    out_snr = snr_db(clean, denoised)\n",
    "    \n",
    "    ax.plot(t, clean, 'g-', lw=2, label='True signal', alpha=0.8)\n",
    "    ax.plot(t, noisy, 'b-', lw=0.5, alpha=0.3, label='Noisy')\n",
    "    ax.plot(t, denoised, 'r-', lw=1.5, label='SSA denoised')\n",
    "    ax.set_title(f'SNR: {in_snr:.1f} dB → {out_snr:.1f} dB  (Δ = +{out_snr-in_snr:.1f} dB)\\nRMSE: {rmse(clean, denoised):.3f}')\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "    ax.set_xlabel('t')\n",
    "\n",
    "plt.suptitle('Test 1: Extreme Low SNR Denoising', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Close Frequency Separation\n",
    "\n",
    "How close can two frequencies be before SSA can't separate them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "t = np.linspace(0, 20, N)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 8))\n",
    "\n",
    "freq_gaps = [0.5, 0.3, 0.2, 0.1]  # Hz difference from 1.0 Hz\n",
    "\n",
    "for idx, delta_f in enumerate(freq_gaps):\n",
    "    f1, f2 = 1.0, 1.0 + delta_f\n",
    "    \n",
    "    s1 = np.sin(2*np.pi*f1*t)\n",
    "    s2 = 0.8*np.sin(2*np.pi*f2*t)\n",
    "    combined = s1 + s2\n",
    "    noisy = combined + 0.2*np.random.randn(N)\n",
    "    \n",
    "    # Adaptive window length (longer for closer frequencies)\n",
    "    L = min(int(3 / delta_f), N//2)\n",
    "    L = max(L, 100)\n",
    "    \n",
    "    ssa = SSA(noisy, L=L)\n",
    "    ssa.decompose(k=10)\n",
    "    \n",
    "    # First two component pairs\n",
    "    comp_a = ssa.reconstruct([0, 1])\n",
    "    comp_b = ssa.reconstruct([2, 3])\n",
    "    \n",
    "    # Which component matches which signal?\n",
    "    corr_a1 = abs(np.corrcoef(comp_a, s1)[0,1])\n",
    "    corr_a2 = abs(np.corrcoef(comp_a, s2)[0,1])\n",
    "    corr_b1 = abs(np.corrcoef(comp_b, s1)[0,1])\n",
    "    corr_b2 = abs(np.corrcoef(comp_b, s2)[0,1])\n",
    "    \n",
    "    # Top: original signals\n",
    "    ax = axes[0, idx]\n",
    "    ax.plot(t[:300], s1[:300], 'g-', lw=2, label=f'f₁={f1} Hz')\n",
    "    ax.plot(t[:300], s2[:300], 'b-', lw=2, label=f'f₂={f2} Hz')\n",
    "    ax.plot(t[:300], noisy[:300], 'k-', lw=0.3, alpha=0.3)\n",
    "    ax.set_title(f'Δf = {delta_f} Hz ({delta_f/f1*100:.0f}%)\\nL = {L}')\n",
    "    ax.legend(fontsize=9)\n",
    "    \n",
    "    # Bottom: extracted components\n",
    "    ax = axes[1, idx]\n",
    "    ax.plot(t[:300], comp_a[:300], 'r-', lw=1.5, label=f'Comp 0,1 (r₁={corr_a1:.2f}, r₂={corr_a2:.2f})')\n",
    "    ax.plot(t[:300], comp_b[:300], 'm-', lw=1.5, label=f'Comp 2,3 (r₁={corr_b1:.2f}, r₂={corr_b2:.2f})')\n",
    "    \n",
    "    # Quality assessment\n",
    "    separation = max(corr_a1, corr_b1) * max(corr_a2, corr_b2)\n",
    "    quality = \"✓ Good\" if separation > 0.8 else \"✗ Mixed\" if separation > 0.5 else \"✗✗ Failed\"\n",
    "    ax.set_title(f'Extracted Components - {quality}')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Test 2: Close Frequency Separation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Non-stationary Signals\n",
    "\n",
    "Amplitude modulation, frequency modulation (chirp), and decaying oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "t = np.linspace(0, 20, N)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "\n",
    "# 3a: Amplitude Modulation\n",
    "envelope = 1 + 0.6*np.sin(2*np.pi*0.15*t)\n",
    "am_clean = envelope * np.sin(2*np.pi*t)\n",
    "am_noisy = am_clean + 0.3*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(am_noisy, L=150)\n",
    "ssa.decompose(k=15)\n",
    "am_recon = ssa.reconstruct([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "axes[0, 0].plot(t, am_clean, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[0, 0].plot(t, am_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[0, 0].plot(t, am_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[0, 0].fill_between(t, -envelope, envelope, alpha=0.1, color='green')\n",
    "axes[0, 0].set_title(f'Amplitude Modulation\\nRMSE: {rmse(am_clean, am_recon):.4f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 3b: Chirp (increasing frequency)\n",
    "inst_freq = 0.5 + 0.5*t/20  # 0.5 Hz → 1.0 Hz\n",
    "phase = 2*np.pi*np.cumsum(inst_freq)/N * 20\n",
    "chirp_clean = np.sin(phase)\n",
    "chirp_noisy = chirp_clean + 0.3*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(chirp_noisy, L=150)\n",
    "ssa.decompose(k=20)\n",
    "chirp_recon = ssa.reconstruct(list(range(8)))\n",
    "\n",
    "axes[0, 1].plot(t, chirp_clean, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[0, 1].plot(t, chirp_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[0, 1].plot(t, chirp_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[0, 1].set_title(f'Chirp (0.5→1.0 Hz)\\nRMSE: {rmse(chirp_clean, chirp_recon):.4f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3c: Decaying oscillation\n",
    "decay_clean = np.exp(-0.15*t) * np.sin(2*np.pi*t)\n",
    "decay_noisy = decay_clean + 0.05*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(decay_noisy, L=100)\n",
    "ssa.decompose(k=15)\n",
    "decay_recon = ssa.reconstruct([0, 1, 2, 3])\n",
    "\n",
    "axes[0, 2].plot(t, decay_clean, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[0, 2].plot(t, decay_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[0, 2].plot(t, decay_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[0, 2].set_title(f'Decaying Oscillation\\nRMSE: {rmse(decay_clean, decay_recon):.4f}')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# 3d: AM + FM combined\n",
    "amfm_clean = envelope * np.sin(phase)\n",
    "amfm_noisy = amfm_clean + 0.3*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(amfm_noisy, L=150)\n",
    "ssa.decompose(k=20)\n",
    "amfm_recon = ssa.reconstruct(list(range(10)))\n",
    "\n",
    "axes[1, 0].plot(t, amfm_clean, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[1, 0].plot(t, amfm_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[1, 0].plot(t, amfm_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[1, 0].set_title(f'AM + FM Combined\\nRMSE: {rmse(amfm_clean, amfm_recon):.4f}')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 3e: Beating (two close frequencies)\n",
    "beat_clean = np.sin(2*np.pi*1.0*t) + np.sin(2*np.pi*1.1*t)\n",
    "beat_noisy = beat_clean + 0.3*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(beat_noisy, L=200)\n",
    "ssa.decompose(k=15)\n",
    "beat_recon = ssa.reconstruct([0, 1, 2, 3])\n",
    "\n",
    "axes[1, 1].plot(t, beat_clean, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[1, 1].plot(t, beat_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[1, 1].plot(t, beat_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[1, 1].set_title(f'Beating (1.0 + 1.1 Hz)\\nRMSE: {rmse(beat_clean, beat_recon):.4f}')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 3f: Exponentially growing\n",
    "grow_clean = np.exp(0.08*t) * np.sin(2*np.pi*t) / 10\n",
    "grow_noisy = grow_clean + 0.1*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(grow_noisy, L=100)\n",
    "ssa.decompose(k=15)\n",
    "grow_recon = ssa.reconstruct(list(range(6)))\n",
    "\n",
    "axes[1, 2].plot(t, grow_clean, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[1, 2].plot(t, grow_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[1, 2].plot(t, grow_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[1, 2].set_title(f'Exponentially Growing\\nRMSE: {rmse(grow_clean, grow_recon):.4f}')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.suptitle('Test 3: Non-stationary Signals', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regime Changes & Structural Breaks\n",
    "\n",
    "Signal properties change abruptly mid-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "t = np.linspace(0, 20, N)\n",
    "mid = N // 2\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "\n",
    "# 4a: Frequency change\n",
    "freq_change = np.zeros(N)\n",
    "freq_change[:mid] = np.sin(2*np.pi*0.5*t[:mid])\n",
    "freq_change[mid:] = np.sin(2*np.pi*1.5*t[mid:])\n",
    "fc_noisy = freq_change + 0.2*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(fc_noisy, L=100)\n",
    "ssa.decompose(k=15)\n",
    "fc_recon = ssa.reconstruct([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "axes[0, 0].plot(t, freq_change, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[0, 0].plot(t, fc_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[0, 0].plot(t, fc_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[0, 0].axvline(t[mid], color='k', ls='--', alpha=0.5)\n",
    "axes[0, 0].set_title(f'Frequency Jump (0.5→1.5 Hz)\\nRMSE: {rmse(freq_change, fc_recon):.4f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 4b: Amplitude change\n",
    "amp_change = np.sin(2*np.pi*t)\n",
    "amp_change[mid:] *= 3\n",
    "ac_noisy = amp_change + 0.3*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(ac_noisy, L=100)\n",
    "ssa.decompose(k=15)\n",
    "ac_recon = ssa.reconstruct([0, 1, 2, 3])\n",
    "\n",
    "axes[0, 1].plot(t, amp_change, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[0, 1].plot(t, ac_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[0, 1].plot(t, ac_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[0, 1].axvline(t[mid], color='k', ls='--', alpha=0.5)\n",
    "axes[0, 1].set_title(f'Amplitude Jump (1x→3x)\\nRMSE: {rmse(amp_change, ac_recon):.4f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 4c: Trend break\n",
    "trend_break = np.zeros(N)\n",
    "trend_break[:mid] = 0.1*t[:mid]\n",
    "trend_break[mid:] = trend_break[mid-1] - 0.15*(t[mid:] - t[mid])\n",
    "trend_break += np.sin(2*np.pi*t)\n",
    "tb_noisy = trend_break + 0.3*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(tb_noisy, L=100)\n",
    "ssa.decompose(k=15)\n",
    "tb_recon = ssa.reconstruct(list(range(6)))\n",
    "tb_trend = ssa.reconstruct([0])\n",
    "\n",
    "axes[1, 0].plot(t, trend_break, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[1, 0].plot(t, tb_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[1, 0].plot(t, tb_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[1, 0].plot(t, tb_trend, 'orange', lw=2, ls='--', label='Trend only')\n",
    "axes[1, 0].axvline(t[mid], color='k', ls='--', alpha=0.5)\n",
    "axes[1, 0].set_title(f'Trend Break (V-shape)\\nRMSE: {rmse(trend_break, tb_recon):.4f}')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4d: Multiple regimes\n",
    "multi_regime = np.zeros(N)\n",
    "third = N // 3\n",
    "multi_regime[:third] = np.sin(2*np.pi*0.5*t[:third]) + 0.05*t[:third]\n",
    "multi_regime[third:2*third] = 2*np.sin(2*np.pi*1.0*t[third:2*third])\n",
    "multi_regime[2*third:] = 0.5*np.sin(2*np.pi*2.0*t[2*third:]) - 0.1*(t[2*third:] - t[2*third])\n",
    "mr_noisy = multi_regime + 0.3*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(mr_noisy, L=80)\n",
    "ssa.decompose(k=20)\n",
    "mr_recon = ssa.reconstruct(list(range(10)))\n",
    "\n",
    "axes[1, 1].plot(t, multi_regime, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "axes[1, 1].plot(t, mr_noisy, 'b-', lw=0.3, alpha=0.3)\n",
    "axes[1, 1].plot(t, mr_recon, 'r-', lw=1.5, label='SSA')\n",
    "axes[1, 1].axvline(t[third], color='k', ls='--', alpha=0.5)\n",
    "axes[1, 1].axvline(t[2*third], color='k', ls='--', alpha=0.5)\n",
    "axes[1, 1].set_title(f'Three Regimes\\nRMSE: {rmse(multi_regime, mr_recon):.4f}')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.suptitle('Test 4: Regime Changes & Structural Breaks', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outliers & Spikes\n",
    "\n",
    "How robust is SSA to anomalies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "t = np.linspace(0, 10, N)\n",
    "clean = np.sin(2*np.pi*t) + 0.3*np.sin(4*np.pi*t)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "\n",
    "# Different outlier scenarios\n",
    "outlier_configs = [\n",
    "    ('1% outliers (5σ)', 0.01, 5),\n",
    "    ('5% outliers (5σ)', 0.05, 5),\n",
    "    ('10% outliers (5σ)', 0.10, 5),\n",
    "    ('1% outliers (10σ)', 0.01, 10),\n",
    "    ('5% outliers (10σ)', 0.05, 10),\n",
    "    ('Single huge spike (50σ)', 0.002, 50),\n",
    "]\n",
    "\n",
    "for idx, (name, frac, magnitude) in enumerate(outlier_configs):\n",
    "    ax = axes[idx//3, idx%3]\n",
    "    \n",
    "    # Add noise and outliers\n",
    "    noisy = clean + 0.2*np.random.randn(N)\n",
    "    n_outliers = max(1, int(N * frac))\n",
    "    outlier_idx = np.random.choice(N, n_outliers, replace=False)\n",
    "    noisy[outlier_idx] += magnitude * np.random.choice([-1, 1], n_outliers)\n",
    "    \n",
    "    # SSA\n",
    "    ssa = SSA(noisy, L=100)\n",
    "    ssa.decompose(k=15)\n",
    "    recon = ssa.reconstruct([0, 1, 2, 3])\n",
    "    \n",
    "    ax.plot(t, clean, 'g-', lw=2, alpha=0.7, label='Clean')\n",
    "    ax.plot(t, noisy, 'b-', lw=0.5, alpha=0.4)\n",
    "    ax.scatter(t[outlier_idx], noisy[outlier_idx], c='blue', s=20, zorder=5)\n",
    "    ax.plot(t, recon, 'r-', lw=1.5, label='SSA')\n",
    "    ax.set_title(f'{name}\\nRMSE: {rmse(clean, recon):.4f}')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_ylim([-3, 3])\n",
    "\n",
    "plt.suptitle('Test 5: Outliers & Spikes', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Financial-like Signals\n",
    "\n",
    "Simulated stock prices, returns, and volatility clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "t = np.arange(N)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "\n",
    "# 6a: GBM with trend\n",
    "returns = 0.0005 + 0.015*np.random.randn(N)  # μ=5bps, σ=1.5%\n",
    "price_gbm = 100 * np.exp(np.cumsum(returns))\n",
    "\n",
    "ssa = SSA(price_gbm, L=200)\n",
    "ssa.decompose(k=20)\n",
    "trend = ssa.reconstruct([0])\n",
    "detrended = price_gbm - trend\n",
    "\n",
    "axes[0, 0].plot(t, price_gbm, 'b-', lw=1, label='Price')\n",
    "axes[0, 0].plot(t, trend, 'r-', lw=2, label='SSA Trend')\n",
    "axes[0, 0].set_title('GBM Stock Price')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_ylabel('Price')\n",
    "\n",
    "# 6b: Mean-reverting (OU process) + seasonality\n",
    "ou = np.zeros(N)\n",
    "theta, mu, sigma = 0.1, 50, 2\n",
    "for i in range(1, N):\n",
    "    ou[i] = ou[i-1] + theta*(mu - ou[i-1]) + sigma*np.random.randn()\n",
    "seasonality = 5*np.sin(2*np.pi*t/50)  # 50-day cycle\n",
    "ou_seasonal = ou + seasonality\n",
    "\n",
    "ssa = SSA(ou_seasonal, L=100)\n",
    "ssa.decompose(k=15)\n",
    "ou_trend = ssa.reconstruct([0])\n",
    "ou_periodic = ssa.reconstruct([1, 2])\n",
    "\n",
    "axes[0, 1].plot(t, ou_seasonal, 'b-', lw=1, label='OU + seasonal')\n",
    "axes[0, 1].plot(t, ou_trend, 'r-', lw=2, label='Trend')\n",
    "axes[0, 1].plot(t, ou_trend + ou_periodic, 'g-', lw=2, label='Trend + Periodic')\n",
    "axes[0, 1].set_title('Mean-Reverting + Seasonality')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 6c: Volatility clustering (GARCH-like)\n",
    "vol = np.ones(N) * 0.01\n",
    "ret_garch = np.zeros(N)\n",
    "for i in range(1, N):\n",
    "    vol[i] = 0.01 + 0.85*vol[i-1] + 0.1*ret_garch[i-1]**2\n",
    "    ret_garch[i] = np.sqrt(vol[i]) * np.random.randn()\n",
    "price_garch = 100 * np.exp(np.cumsum(ret_garch))\n",
    "\n",
    "ssa = SSA(price_garch, L=150)\n",
    "ssa.decompose(k=20)\n",
    "garch_trend = ssa.reconstruct([0])\n",
    "\n",
    "axes[0, 2].plot(t, price_garch, 'b-', lw=1, label='Price')\n",
    "axes[0, 2].plot(t, garch_trend, 'r-', lw=2, label='SSA Trend')\n",
    "axes[0, 2].set_title('GARCH-like (Vol Clustering)')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# 6d: Jump diffusion\n",
    "returns_jd = 0.0003 + 0.012*np.random.randn(N)\n",
    "jumps = (np.random.rand(N) < 0.02) * np.random.randn(N) * 0.05  # 2% chance of 5% jump\n",
    "returns_jd += jumps\n",
    "price_jd = 100 * np.exp(np.cumsum(returns_jd))\n",
    "\n",
    "ssa = SSA(price_jd, L=150)\n",
    "ssa.decompose(k=15)\n",
    "jd_trend = ssa.reconstruct([0])\n",
    "\n",
    "axes[1, 0].plot(t, price_jd, 'b-', lw=1, label='Price')\n",
    "axes[1, 0].plot(t, jd_trend, 'r-', lw=2, label='SSA Trend')\n",
    "axes[1, 0].scatter(t[jumps != 0], price_jd[jumps != 0], c='orange', s=20, label='Jumps')\n",
    "axes[1, 0].set_title('Jump Diffusion')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 6e: Pairs trading setup (cointegrated series)\n",
    "common = np.cumsum(0.01*np.random.randn(N))\n",
    "stock_a = 100 + common + 0.5*np.random.randn(N)\n",
    "stock_b = 50 + 0.5*common + 0.3*np.random.randn(N)\n",
    "spread = stock_a - 2*stock_b\n",
    "\n",
    "ssa = SSA(spread, L=100)\n",
    "ssa.decompose(k=10)\n",
    "spread_smooth = ssa.reconstruct([0, 1, 2])\n",
    "spread_mean = np.mean(spread)\n",
    "spread_std = np.std(spread)\n",
    "\n",
    "axes[1, 1].plot(t, spread, 'b-', lw=0.5, alpha=0.5, label='Raw spread')\n",
    "axes[1, 1].plot(t, spread_smooth, 'r-', lw=2, label='SSA smoothed')\n",
    "axes[1, 1].axhline(spread_mean, color='k', ls='--', alpha=0.5)\n",
    "axes[1, 1].axhline(spread_mean + 2*spread_std, color='g', ls=':', label='±2σ')\n",
    "axes[1, 1].axhline(spread_mean - 2*spread_std, color='g', ls=':')\n",
    "axes[1, 1].set_title('Pairs Trading Spread')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 6f: Forecasting test\n",
    "N_train = 800\n",
    "signal = 100 + 0.05*t + 10*np.sin(2*np.pi*t/100) + 3*np.random.randn(N)\n",
    "\n",
    "ssa = SSA(signal[:N_train], L=200)\n",
    "ssa.decompose(k=20)\n",
    "forecast = ssa.forecast([0, 1, 2], n_forecast=N-N_train)\n",
    "reconstruction = ssa.reconstruct([0, 1, 2])\n",
    "\n",
    "axes[1, 2].plot(t[:N_train], signal[:N_train], 'b-', lw=1, label='Training data')\n",
    "axes[1, 2].plot(t[N_train:], signal[N_train:], 'g-', lw=2, label='True future')\n",
    "axes[1, 2].plot(t[:N_train], reconstruction, 'r-', lw=1, alpha=0.7)\n",
    "axes[1, 2].plot(t[N_train:], forecast, 'r--', lw=2, label='SSA forecast')\n",
    "axes[1, 2].axvline(N_train, color='k', ls='--', alpha=0.5)\n",
    "axes[1, 2].set_title(f'Forecasting (RMSE: {rmse(signal[N_train:], forecast):.2f})')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.suptitle('Test 6: Financial-like Signals', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MSSA: Correlated Multi-series Analysis\n",
    "\n",
    "Extract common factors from multiple related time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "t = np.linspace(0, 10, N)\n",
    "\n",
    "# Common market factor\n",
    "market = 0.05*t + 2*np.sin(2*np.pi*0.5*t)\n",
    "\n",
    "# 5 \"stocks\" with different betas and idiosyncratic components\n",
    "betas = [1.0, 0.8, 1.2, 0.6, 1.4]\n",
    "stocks = []\n",
    "for i, beta in enumerate(betas):\n",
    "    idio = 0.5*np.sin(2*np.pi*(1 + 0.3*i)*t + i)  # Different frequencies\n",
    "    noise = 0.3*np.random.randn(N)\n",
    "    stocks.append(beta * market + idio + noise)\n",
    "\n",
    "X = np.array(stocks)\n",
    "\n",
    "# Run MSSA\n",
    "mssa = MSSA(X, L=100)\n",
    "mssa.decompose(k=15)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "\n",
    "# Plot original series\n",
    "ax = axes[0, 0]\n",
    "for i in range(5):\n",
    "    ax.plot(t, stocks[i], lw=1, alpha=0.7, label=f'Stock {i+1} (β={betas[i]})')\n",
    "ax.set_title('Original Series')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# Extract common factor (first component)\n",
    "common_extracted = mssa.reconstruct_all([0])\n",
    "ax = axes[0, 1]\n",
    "ax.plot(t, market, 'k-', lw=3, label='True market factor')\n",
    "for i in range(5):\n",
    "    ax.plot(t, common_extracted[i] / betas[i], '--', lw=1, alpha=0.7, label=f'Extracted/{betas[i]}')\n",
    "ax.set_title('Common Factor Extraction')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# Series contributions\n",
    "contrib = mssa.series_contributions()\n",
    "ax = axes[0, 2]\n",
    "im = ax.imshow(contrib[:, :10], aspect='auto', cmap='Blues')\n",
    "ax.set_xlabel('Component')\n",
    "ax.set_ylabel('Series')\n",
    "ax.set_yticks(range(5))\n",
    "ax.set_yticklabels([f'Stock {i+1}' for i in range(5)])\n",
    "plt.colorbar(im, ax=ax)\n",
    "ax.set_title('Series Contributions by Component')\n",
    "\n",
    "# Residuals after removing common factor\n",
    "residuals = X - common_extracted\n",
    "ax = axes[1, 0]\n",
    "for i in range(5):\n",
    "    ax.plot(t, residuals[i], lw=1, alpha=0.7, label=f'Stock {i+1}')\n",
    "ax.set_title('Residuals (Idiosyncratic)')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# Residual correlation matrix\n",
    "residual_corr = np.corrcoef(residuals)\n",
    "ax = axes[1, 1]\n",
    "im = ax.imshow(residual_corr, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax.set_title('Residual Correlations\\n(should be ~0)')\n",
    "plt.colorbar(im, ax=ax)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax.text(j, i, f'{residual_corr[i,j]:.2f}', ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Variance explained\n",
    "ax = axes[1, 2]\n",
    "var_exp = [mssa.variance_explained(i, i) for i in range(15)]\n",
    "ax.bar(range(15), var_exp)\n",
    "ax.set_xlabel('Component')\n",
    "ax.set_ylabel('Variance Explained')\n",
    "ax.set_title(f'Variance Spectrum\\nFirst 3: {sum(var_exp[:3]):.1%}')\n",
    "\n",
    "plt.suptitle('Test 7: MSSA Multi-series Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Scaling\n",
    "\n",
    "How does performance scale with N, L, and k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "results = []\n",
    "\n",
    "# Test different sizes\n",
    "for N in [500, 1000, 2000, 5000, 10000]:\n",
    "    L = N // 5\n",
    "    k = 50\n",
    "    x = np.sin(np.linspace(0, 20*np.pi, N)) + 0.3*np.random.randn(N)\n",
    "    \n",
    "    # Warmup\n",
    "    ssa = SSA(x, L=L)\n",
    "    ssa.decompose(k=k)\n",
    "    \n",
    "    # Timed runs\n",
    "    times = []\n",
    "    for _ in range(3):\n",
    "        t0 = time.perf_counter()\n",
    "        ssa = SSA(x, L=L)\n",
    "        ssa.decompose(k=k)\n",
    "        _ = ssa.reconstruct(list(range(k)))\n",
    "        times.append(time.perf_counter() - t0)\n",
    "    \n",
    "    avg_time = np.mean(times) * 1000\n",
    "    results.append((N, L, k, avg_time))\n",
    "    print(f\"N={N:5d}, L={L:4d}, k={k}: {avg_time:.1f} ms\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "Ns = [r[0] for r in results]\n",
    "times_ms = [r[3] for r in results]\n",
    "ax.plot(Ns, times_ms, 'bo-', lw=2, markersize=10)\n",
    "ax.set_xlabel('Signal Length (N)')\n",
    "ax.set_ylabel('Time (ms)')\n",
    "ax.set_title('SSA Performance Scaling')\n",
    "ax.grid(True)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key findings:\n",
    "- **Low SNR**: SSA provides ~10-15 dB improvement even at very low SNR\n",
    "- **Close frequencies**: Need longer window (L) for better separation\n",
    "- **Non-stationary**: AM works well, FM (chirp) is harder\n",
    "- **Regime changes**: SSA smooths transitions, may miss abrupt changes\n",
    "- **Outliers**: Surprisingly robust for small outlier fraction\n",
    "- **Financial data**: Good trend extraction, forecasting works for trending signals\n",
    "- **MSSA**: Effectively extracts common factors from correlated series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
